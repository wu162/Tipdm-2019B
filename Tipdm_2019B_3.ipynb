{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tipdm_2019B_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wu162/Tipdm-2019B/blob/master/Tipdm_2019B_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7XmJAZeriBbL",
        "colab_type": "code",
        "outputId": "6e5df3d8-bcff-4be9-c09e-857e3b73fac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 10.2 GB  | Proc size: 4.4 GB\n",
            "GPU RAM Free: 468MB | Used: 14611MB | Util  97% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kT4VpS8fi8lP",
        "colab_type": "code",
        "outputId": "4eb9e0b9-0f44-49ee-f5f7-ede8f128f1cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131304 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dCUDOtPLi9NO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 指定Google Drive云端硬盘的根目录，名为drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBDU7Jhijx9j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 指定当前的工作文件夹\n",
        "import os\n",
        "\n",
        "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
        "os.chdir(\"drive/Tipdm-2019B/\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tx86W2tTj2m-",
        "colab_type": "code",
        "outputId": "0f487445-5a59-409c-b843-f599359d3f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ct_scan  test_img\t      Tipdm_2019B_2.ipynb  unet_Noaug_256_1.h5\n",
            "drive\t test_mask\t      unet_256_1.hdf5\t   unet_Noaug_256_2.h5\n",
            "mask\t Tipdm_2019B_1.ipynb  unet_membrane.hdf5   unet_Noaug_3.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ukH1xhWVMfdL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#start from here\n",
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "#from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(2019)\n",
        "tf.set_random_seed(2019)\n",
        "\n",
        "smooth = 1\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection+smooth) / (K.sum(y_true_f) + K.sum(y_pred_f)+smooth)\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return  binary_crossentropy(y_true, y_pred) + 1 - dice_coef(y_true, y_pred)\n",
        "    #return  1-dice_coef(y_true, y_pred)\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def iou_coef_loss(y_true, y_pred):\n",
        "    return 0.5*binary_crossentropy(y_true, y_pred)+1-iou_coef(y_true, y_pred)\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (512,512,1)):\n",
        "    inputs = Input(input_size)\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "    c1 = Dropout(0.1) (c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "    c2 = Dropout(0.1) (c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "    c3 = Dropout(0.2) (c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "    c4 = Dropout(0.2) (c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "    c5 = Dropout(0.3) (c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "    c6 = Dropout(0.2) (c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "    c7 = Dropout(0.2) (c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "    c8 = Dropout(0.1) (c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "    c9 = Dropout(0.1) (c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    model.compile(Adam(lr = 1e-5),binary_crossentropy, metrics = ['accuracy',dice_coef])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "      \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ISURtC8PavCc",
        "colab_type": "code",
        "outputId": "e1b856fa-e772-478c-c8d0-2b214c86252f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import scipy.misc\n",
        "\n",
        "img2=scipy.misc.imread('./ct_scan/train_img/1001_10001.png',mode='I')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P3lL5sPO5Yfd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lt5rl5O9tgmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_path='./ct_scan/train_img/'\n",
        "y_path='./mask/train_mask/'\n",
        "x_files_names=os.listdir(X_path)\n",
        "y_files_names=os.listdir(y_path)\n",
        "x_files=np.array([X_path+file for file in x_files_names])\n",
        "y_files=np.array([y_path+file for file in y_files_names])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qHvENnqEt0jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "index=list(range(len(x_files)))\n",
        "test_index=random.sample(index, 500)\n",
        "train_index=list(set(index) - set(test_index))\n",
        "x_files_train=x_files[train_index].tolist()\n",
        "y_files_train=y_files[train_index].tolist()\n",
        "x_files_test=x_files[test_index].tolist()\n",
        "y_files_test=y_files[test_index].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzKKhhCPrKIC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c704a5d6-9da4-4a54-d107-09643d7ec5d5"
      },
      "cell_type": "code",
      "source": [
        "len(y_files_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "ee3AmrRkBnZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc\n",
        "%matplotlib inline\n",
        "\n",
        "def get_train_batch(X_path, y_path, batch_size):\n",
        "    while 1:\n",
        "        for i in range(0, len(X_path), batch_size):\n",
        "            x = np.array([scipy.misc.imread(path,mode='I') for path in X_path[i:i+batch_size]])\n",
        "            y = np.array([plt.imread(path) for path in y_path[i:i+batch_size]])\n",
        "            y=y==1\n",
        "            x=x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n",
        "            y=y.reshape(y.shape[0],y.shape[1],y.shape[2],1)\n",
        "            yield x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tz82d6OQ1oJs",
        "colab_type": "code",
        "outputId": "ac715047-1ae9-4cf2-b3a9-522f335823be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11971
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size=8\n",
        "model_checkpoint=ModelCheckpoint('unet_Noaug_4.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model=unet(input_size = (256,256,1))\n",
        "model.load_weights('unet_Noaug_3.hdf5')\n",
        "model.fit_generator(get_train_batch(x_files_train,y_files_train,batch_size),steps_per_epoch=2529/batch_size,epochs=300,validation_data=get_train_batch(x_files_test,y_files_test,batch_size),validation_steps=500/batch_size,callbacks=[model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "317/316 [==============================] - 2884s 9s/step - loss: 9.6537 - acc: 0.3749 - dice_coef: 0.0125 - val_loss: 4.0590 - val_acc: 0.7390 - val_dice_coef: 0.0126\n",
            "\n",
            "Epoch 00001: loss improved from inf to 9.66785, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 2/300\n",
            "317/316 [==============================] - 35s 111ms/step - loss: 2.8244 - acc: 0.8143 - dice_coef: 0.0097 - val_loss: 0.1465 - val_acc: 0.9900 - val_dice_coef: 2.2295e-04\n",
            "\n",
            "Epoch 00002: loss improved from 9.66785 to 2.83068, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 3/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1799 - acc: 0.9865 - dice_coef: 0.0021 - val_loss: 0.1297 - val_acc: 0.9911 - val_dice_coef: 2.5754e-04\n",
            "\n",
            "Epoch 00003: loss improved from 2.83068 to 0.17917, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 4/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1433 - acc: 0.9898 - dice_coef: 0.0012 - val_loss: 0.1237 - val_acc: 0.9920 - val_dice_coef: 3.2200e-04\n",
            "\n",
            "Epoch 00004: loss improved from 0.17917 to 0.14252, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 5/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1297 - acc: 0.9911 - dice_coef: 9.1316e-04 - val_loss: 0.1209 - val_acc: 0.9923 - val_dice_coef: 3.5789e-04\n",
            "\n",
            "Epoch 00005: loss improved from 0.14252 to 0.12884, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 6/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1198 - acc: 0.9920 - dice_coef: 7.4863e-04 - val_loss: 0.1090 - val_acc: 0.9932 - val_dice_coef: 6.7367e-04\n",
            "\n",
            "Epoch 00006: loss improved from 0.12884 to 0.11898, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 7/300\n",
            "317/316 [==============================] - 35s 109ms/step - loss: 0.1131 - acc: 0.9926 - dice_coef: 6.9516e-04 - val_loss: 0.1088 - val_acc: 0.9932 - val_dice_coef: 8.9167e-04\n",
            "\n",
            "Epoch 00007: loss improved from 0.11898 to 0.11230, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 8/300\n",
            "317/316 [==============================] - 35s 112ms/step - loss: 0.1099 - acc: 0.9929 - dice_coef: 7.6297e-04 - val_loss: 0.1087 - val_acc: 0.9932 - val_dice_coef: 0.0011\n",
            "\n",
            "Epoch 00008: loss improved from 0.11230 to 0.10909, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 9/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1082 - acc: 0.9931 - dice_coef: 8.1061e-04 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0013\n",
            "\n",
            "Epoch 00009: loss improved from 0.10909 to 0.10731, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 10/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1071 - acc: 0.9932 - dice_coef: 8.9800e-04 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0015\n",
            "\n",
            "Epoch 00010: loss improved from 0.10731 to 0.10626, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 11/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1064 - acc: 0.9933 - dice_coef: 0.0011 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0017\n",
            "\n",
            "Epoch 00011: loss improved from 0.10626 to 0.10555, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 12/300\n",
            "317/316 [==============================] - 35s 110ms/step - loss: 0.1059 - acc: 0.9933 - dice_coef: 0.0012 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0019\n",
            "\n",
            "Epoch 00012: loss improved from 0.10555 to 0.10505, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 13/300\n",
            "317/316 [==============================] - 34s 109ms/step - loss: 0.1055 - acc: 0.9934 - dice_coef: 0.0014 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0021\n",
            "\n",
            "Epoch 00013: loss improved from 0.10505 to 0.10469, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 14/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1053 - acc: 0.9934 - dice_coef: 0.0016 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0024\n",
            "\n",
            "Epoch 00014: loss improved from 0.10469 to 0.10444, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 15/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1051 - acc: 0.9934 - dice_coef: 0.0019 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0026\n",
            "\n",
            "Epoch 00015: loss improved from 0.10444 to 0.10424, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 16/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1049 - acc: 0.9935 - dice_coef: 0.0022 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0029\n",
            "\n",
            "Epoch 00016: loss improved from 0.10424 to 0.10409, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 17/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1048 - acc: 0.9935 - dice_coef: 0.0027 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0031\n",
            "\n",
            "Epoch 00017: loss improved from 0.10409 to 0.10397, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 18/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1047 - acc: 0.9935 - dice_coef: 0.0031 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0034\n",
            "\n",
            "Epoch 00018: loss improved from 0.10397 to 0.10388, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 19/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1047 - acc: 0.9935 - dice_coef: 0.0034 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0037\n",
            "\n",
            "Epoch 00019: loss improved from 0.10388 to 0.10383, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 20/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1046 - acc: 0.9935 - dice_coef: 0.0041 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0040\n",
            "\n",
            "Epoch 00020: loss improved from 0.10383 to 0.10377, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 21/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1046 - acc: 0.9935 - dice_coef: 0.0047 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0043\n",
            "\n",
            "Epoch 00021: loss improved from 0.10377 to 0.10373, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 22/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1045 - acc: 0.9935 - dice_coef: 0.0056 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0047\n",
            "\n",
            "Epoch 00022: loss improved from 0.10373 to 0.10369, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 23/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1045 - acc: 0.9935 - dice_coef: 0.0061 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0051\n",
            "\n",
            "Epoch 00023: loss improved from 0.10369 to 0.10366, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 24/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1045 - acc: 0.9935 - dice_coef: 0.0075 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0055\n",
            "\n",
            "Epoch 00024: loss improved from 0.10366 to 0.10364, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 25/300\n",
            "317/316 [==============================] - 35s 109ms/step - loss: 0.1045 - acc: 0.9935 - dice_coef: 0.0081 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0060\n",
            "\n",
            "Epoch 00025: loss improved from 0.10364 to 0.10363, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 26/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0099 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0065\n",
            "\n",
            "Epoch 00026: loss improved from 0.10363 to 0.10361, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 27/300\n",
            "317/316 [==============================] - 35s 109ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0116 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0069\n",
            "\n",
            "Epoch 00027: loss improved from 0.10361 to 0.10360, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 28/300\n",
            "317/316 [==============================] - 37s 117ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0134 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0075\n",
            "\n",
            "Epoch 00028: loss improved from 0.10360 to 0.10359, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 29/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0145 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0081\n",
            "\n",
            "Epoch 00029: loss improved from 0.10359 to 0.10358, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 30/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0157 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0087\n",
            "\n",
            "Epoch 00030: loss improved from 0.10358 to 0.10357, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 31/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0172 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0094\n",
            "\n",
            "Epoch 00031: loss improved from 0.10357 to 0.10357, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 32/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0184 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0100\n",
            "\n",
            "Epoch 00032: loss improved from 0.10357 to 0.10356, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 33/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0240 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0108\n",
            "\n",
            "Epoch 00033: loss improved from 0.10356 to 0.10356, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 34/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0267 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0115\n",
            "\n",
            "Epoch 00034: loss improved from 0.10356 to 0.10355, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 35/300\n",
            "317/316 [==============================] - 33s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0287 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0123\n",
            "\n",
            "Epoch 00035: loss improved from 0.10355 to 0.10355, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 36/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0310 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0132\n",
            "\n",
            "Epoch 00036: loss improved from 0.10355 to 0.10355, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 37/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0390 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0139\n",
            "\n",
            "Epoch 00037: loss improved from 0.10355 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 38/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0369 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0150\n",
            "\n",
            "Epoch 00038: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 39/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0417 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0162\n",
            "\n",
            "Epoch 00039: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 40/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0447 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0169\n",
            "\n",
            "Epoch 00040: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 41/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0485 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0177\n",
            "\n",
            "Epoch 00041: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 42/300\n",
            "317/316 [==============================] - 35s 110ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0507 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0182\n",
            "\n",
            "Epoch 00042: loss did not improve from 0.10354\n",
            "Epoch 43/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0492 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0191\n",
            "\n",
            "Epoch 00043: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 44/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0574 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0204\n",
            "\n",
            "Epoch 00044: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 45/300\n",
            "317/316 [==============================] - 35s 109ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0600 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0202\n",
            "\n",
            "Epoch 00045: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 46/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0638 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0214\n",
            "\n",
            "Epoch 00046: loss improved from 0.10354 to 0.10354, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 47/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0652 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0221\n",
            "\n",
            "Epoch 00047: loss improved from 0.10354 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 48/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0692 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0232\n",
            "\n",
            "Epoch 00048: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 49/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0715 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0239\n",
            "\n",
            "Epoch 00049: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 50/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0685 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0248\n",
            "\n",
            "Epoch 00050: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 51/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0686 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0253\n",
            "\n",
            "Epoch 00051: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 52/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0775 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0261\n",
            "\n",
            "Epoch 00052: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 53/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0779 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0262\n",
            "\n",
            "Epoch 00053: loss did not improve from 0.10353\n",
            "Epoch 54/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0808 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0268\n",
            "\n",
            "Epoch 00054: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 55/300\n",
            "317/316 [==============================] - 33s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0830 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0276\n",
            "\n",
            "Epoch 00055: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 56/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0817 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0280\n",
            "\n",
            "Epoch 00056: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 57/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0819 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0286\n",
            "\n",
            "Epoch 00057: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 58/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0855 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0292\n",
            "\n",
            "Epoch 00058: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 59/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0873 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0295\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.10353\n",
            "Epoch 60/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0831 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0299\n",
            "\n",
            "Epoch 00060: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 61/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0866 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0299\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.10353\n",
            "Epoch 62/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0851 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0302\n",
            "\n",
            "Epoch 00062: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 63/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0890 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0304\n",
            "\n",
            "Epoch 00063: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 64/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0894 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0307\n",
            "\n",
            "Epoch 00064: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 65/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0898 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0311\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.10353\n",
            "Epoch 66/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0887 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0313\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.10353\n",
            "Epoch 67/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0897 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0311\n",
            "\n",
            "Epoch 00067: loss did not improve from 0.10353\n",
            "Epoch 68/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0882 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0310\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.10353\n",
            "Epoch 69/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0905 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0313\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.10353\n",
            "Epoch 70/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0902 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0315\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.10353\n",
            "Epoch 71/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0905 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0316\n",
            "\n",
            "Epoch 00071: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 72/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0912 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0317\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.10353\n",
            "Epoch 73/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0909 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0317\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.10353\n",
            "Epoch 74/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0906 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0318\n",
            "\n",
            "Epoch 00074: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 75/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0908 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0319\n",
            "\n",
            "Epoch 00075: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 76/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0904 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0320\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.10353\n",
            "Epoch 77/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0910 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0320\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.10353\n",
            "Epoch 78/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0915 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0321\n",
            "\n",
            "Epoch 00078: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 79/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0915 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0321\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.10353\n",
            "Epoch 80/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0916 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0322\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.10353\n",
            "Epoch 81/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0899 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0322\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.10353\n",
            "Epoch 82/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0904 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0322\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.10353\n",
            "Epoch 83/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0911 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0322\n",
            "\n",
            "Epoch 00083: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 84/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0916 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0322\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.10353\n",
            "Epoch 85/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0916 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0322\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.10353\n",
            "Epoch 86/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0917 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.10353\n",
            "Epoch 87/300\n",
            "317/316 [==============================] - 33s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0916 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00087: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 88/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0914 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00088: loss did not improve from 0.10353\n",
            "Epoch 89/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0917 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00089: loss did not improve from 0.10353\n",
            "Epoch 90/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0917 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00090: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 91/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0914 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00091: loss did not improve from 0.10353\n",
            "Epoch 92/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.10353\n",
            "Epoch 93/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00093: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 94/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0917 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00094: loss did not improve from 0.10353\n",
            "Epoch 95/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00095: loss did not improve from 0.10353\n",
            "Epoch 96/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00096: loss did not improve from 0.10353\n",
            "Epoch 97/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0323\n",
            "\n",
            "Epoch 00097: loss did not improve from 0.10353\n",
            "Epoch 98/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00098: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 99/300\n",
            "317/316 [==============================] - 34s 108ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00099: loss did not improve from 0.10353\n",
            "Epoch 100/300\n",
            "317/316 [==============================] - 35s 109ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00100: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 101/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00101: loss did not improve from 0.10353\n",
            "Epoch 102/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00102: loss did not improve from 0.10353\n",
            "Epoch 103/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00103: loss did not improve from 0.10353\n",
            "Epoch 104/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00104: loss did not improve from 0.10353\n",
            "Epoch 105/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00105: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 106/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00106: loss did not improve from 0.10353\n",
            "Epoch 107/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00107: loss did not improve from 0.10353\n",
            "Epoch 108/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00108: loss did not improve from 0.10353\n",
            "Epoch 109/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00109: loss did not improve from 0.10353\n",
            "Epoch 110/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00110: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 111/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00111: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 112/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00112: loss did not improve from 0.10353\n",
            "Epoch 113/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00113: loss did not improve from 0.10353\n",
            "Epoch 114/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00114: loss did not improve from 0.10353\n",
            "Epoch 115/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00115: loss did not improve from 0.10353\n",
            "Epoch 116/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00116: loss did not improve from 0.10353\n",
            "Epoch 117/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00117: loss did not improve from 0.10353\n",
            "Epoch 118/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0917 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00118: loss did not improve from 0.10353\n",
            "Epoch 119/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00119: loss did not improve from 0.10353\n",
            "Epoch 120/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00120: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 121/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0909 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00121: loss did not improve from 0.10353\n",
            "Epoch 122/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00122: loss did not improve from 0.10353\n",
            "Epoch 123/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00123: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 124/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.10353\n",
            "Epoch 125/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00125: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 126/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.10353\n",
            "Epoch 127/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.10353\n",
            "Epoch 128/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.10353\n",
            "Epoch 129/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.10353\n",
            "Epoch 130/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.10353\n",
            "Epoch 131/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00131: loss did not improve from 0.10353\n",
            "Epoch 132/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00132: loss did not improve from 0.10353\n",
            "Epoch 133/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00133: loss did not improve from 0.10353\n",
            "Epoch 134/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00134: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 135/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00135: loss did not improve from 0.10353\n",
            "Epoch 136/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00136: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 137/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00137: loss did not improve from 0.10353\n",
            "Epoch 138/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00138: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 139/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00139: loss did not improve from 0.10353\n",
            "Epoch 140/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00140: loss did not improve from 0.10353\n",
            "Epoch 141/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00141: loss did not improve from 0.10353\n",
            "Epoch 142/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00142: loss did not improve from 0.10353\n",
            "Epoch 143/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00143: loss did not improve from 0.10353\n",
            "Epoch 144/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00144: loss did not improve from 0.10353\n",
            "Epoch 145/300\n",
            "317/316 [==============================] - 32s 101ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00145: loss did not improve from 0.10353\n",
            "Epoch 146/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00146: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 147/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00147: loss did not improve from 0.10353\n",
            "Epoch 148/300\n",
            "317/316 [==============================] - 32s 101ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00148: loss did not improve from 0.10353\n",
            "Epoch 149/300\n",
            "317/316 [==============================] - 32s 102ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00149: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 150/300\n",
            "317/316 [==============================] - 32s 101ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00150: loss did not improve from 0.10353\n",
            "Epoch 151/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00151: loss did not improve from 0.10353\n",
            "Epoch 152/300\n",
            "317/316 [==============================] - 33s 103ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0903 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00152: loss did not improve from 0.10353\n",
            "Epoch 153/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00153: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 154/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00154: loss did not improve from 0.10353\n",
            "Epoch 155/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00155: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 156/300\n",
            "317/316 [==============================] - 33s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00156: loss did not improve from 0.10353\n",
            "Epoch 157/300\n",
            "317/316 [==============================] - 33s 104ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00157: loss did not improve from 0.10353\n",
            "Epoch 158/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00158: loss did not improve from 0.10353\n",
            "Epoch 159/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00159: loss did not improve from 0.10353\n",
            "Epoch 160/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00160: loss did not improve from 0.10353\n",
            "Epoch 161/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00161: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 162/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00162: loss did not improve from 0.10353\n",
            "Epoch 163/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0918 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00163: loss did not improve from 0.10353\n",
            "Epoch 164/300\n",
            "317/316 [==============================] - 33s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00164: loss did not improve from 0.10353\n",
            "Epoch 165/300\n",
            "317/316 [==============================] - 34s 106ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00165: loss did not improve from 0.10353\n",
            "Epoch 166/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00166: loss did not improve from 0.10353\n",
            "Epoch 167/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00167: loss did not improve from 0.10353\n",
            "Epoch 168/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00168: loss improved from 0.10353 to 0.10353, saving model to unet_Noaug_3.hdf5\n",
            "Epoch 169/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00169: loss did not improve from 0.10353\n",
            "Epoch 170/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00170: loss did not improve from 0.10353\n",
            "Epoch 171/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00171: loss did not improve from 0.10353\n",
            "Epoch 172/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00172: loss did not improve from 0.10353\n",
            "Epoch 173/300\n",
            "317/316 [==============================] - 34s 107ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00173: loss did not improve from 0.10353\n",
            "Epoch 174/300\n",
            "317/316 [==============================] - 33s 105ms/step - loss: 0.1044 - acc: 0.9935 - dice_coef: 0.0919 - val_loss: 0.1086 - val_acc: 0.9933 - val_dice_coef: 0.0324\n",
            "\n",
            "Epoch 00174: loss did not improve from 0.10353\n",
            "Epoch 175/300\n",
            "248/316 [======================>.......] - ETA: 6s - loss: 0.1010 - acc: 0.9937 - dice_coef: 0.0972Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sS6FdFAaMI1W",
        "colab_type": "code",
        "outputId": "51872e91-6358-4411-af6f-6dbfc05cfbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "path='./ct_scan/train_img/'\n",
        "files=os.listdir(path)\n",
        "files=files[0:200]\n",
        "img=[scipy.misc.imread(path+file,mode='I') for file in files]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zw57JY4mM3Bo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path='./mask/train_mask/'\n",
        "files=os.listdir(path)\n",
        "files=files[0:200]\n",
        "mask=[plt.imread(path+file) for file in files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o12eUOESNeIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img=np.array(img)\n",
        "mask=np.array(mask)\n",
        "mask=mask==1\n",
        "img2=img.reshape(img.shape[0],img.shape[1],img.shape[2],1)\n",
        "mask2=mask.reshape(mask.shape[0],mask.shape[1],mask.shape[2],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFizN06-NOO_",
        "colab_type": "code",
        "outputId": "aed1ef18-4334-47e4-fd32-d2578f7b665e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(img2,mask2,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 4s 20ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1002488390868325, 0.9937803649902344, 0.04008594109676778]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "KXV6ayyaPuJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds=model.predict(img2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C7Oe22GuZI8f",
        "colab_type": "code",
        "outputId": "2dcd555c-3e80-47c2-9215-9de549203956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.max(preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.013926059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "dWykFx3qP0ts",
        "colab_type": "code",
        "outputId": "852c1f96-6027-4c86-a9e4-5d80bedaed89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "cell_type": "code",
      "source": [
        "ix=11\n",
        "plt.imshow(np.squeeze(preds[ix]))\n",
        "plt.show()\n",
        "plt.imshow(mask[ix])\n",
        "plt.show()\n",
        "plt.imshow(img[ix])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGCQ1DIOkhmGQ1DAMkhqGQVLj/wBEtnhrDHdyQwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npMYwSGoMg6TGMEhqDIOkxjBIav4XoTFm+s1FrB0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nozua0f8DMOsm9k3uPT8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zbBtXDAgW6Sp",
        "colab_type": "code",
        "outputId": "c2dafa35-989b-447a-ae2c-cae5be668ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1804
        }
      },
      "cell_type": "code",
      "source": [
        "x_folder='./ct_scan/train_img/'\n",
        "y_folder='./mask/train_mask/'\n",
        "x_files=os.listdir(x_folder)\n",
        "y_files=os.listdir(y_folder)\n",
        "x_files.sort()\n",
        "y_files.sort()\n",
        "x_files=x_files[0:200]\n",
        "y_files=y_files[0:200]\n",
        "for i in range(len(x_files)):\n",
        "  x=scipy.misc.imread(x_folder+x_files[i],mode='I')\n",
        "  y=plt.imread(y_folder+y_files[i])\n",
        "  x=x.reshape(1,x.shape[0],x.shape[1],1)\n",
        "  y=y.reshape(1,y.shape[0],y.shape[1],1)\n",
        "  score=model.evaluate(x,y,verbose=0)\n",
        "  print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[0.39252448081970215, 0.97564697265625, 0.0006261740927584469]\n",
            "[0.5501736402511597, 0.9658660888671875, 0.0004468275292310864]\n",
            "[0.45966681838035583, 0.9714813232421875, 0.0005347593687474728]\n",
            "[0.28234219551086426, 0.98248291015625, 0.0008703219937160611]\n",
            "[0.2233159840106964, 0.98614501953125, 0.001100110006518662]\n",
            "[0.23561310768127441, 0.985382080078125, 0.0010427528759464622]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[0.2513534426689148, 0.984405517578125, 0.0009775171056389809]\n",
            "[0.25602632761001587, 0.9841156005859375, 0.0009596928721293807]\n",
            "[0.30693644285202026, 0.98095703125, 0.0008006404968909919]\n",
            "[0.34112247824668884, 0.9788360595703125, 0.0007204610737971961]\n",
            "[0.40310001373291016, 0.9749908447265625, 0.0006097560981288552]\n",
            "[0.36227357387542725, 0.9775238037109375, 0.0006784260622225702]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[0.29857438802719116, 0.981475830078125, 0.0008230452658608556]\n",
            "[0.4072810411453247, 0.9747314453125, 0.0006035002879798412]\n",
            "[0.3369414210319519, 0.979095458984375, 0.0007293946109712124]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n",
            "[1.0000001537946446e-07, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-e0f8d6b604a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}